"""
ç¡¬ä»¶æ£€æµ‹æ¨¡å—
Hardware Detection Module

ç”¨äºè‡ªåŠ¨æ£€æµ‹GPUã€CPUã€å†…å­˜ç­‰ç¡¬ä»¶ä¿¡æ¯ï¼Œä¸ºæ€§èƒ½ä¼˜åŒ–æä¾›åŸºç¡€æ•°æ®ã€‚
"""

import torch
import psutil
import platform
import logging
from dataclasses import dataclass
from typing import Optional

logger = logging.getLogger(__name__)


@dataclass
class GPUInfo:
    """GPUä¿¡æ¯"""
    available: bool
    device_name: str
    vram_total_gb: float
    vram_available_gb: float
    cuda_version: Optional[str] = None
    device_count: int = 0

    def __post_init__(self):
        if self.available and self.cuda_version is None:
            try:
                self.cuda_version = torch.version.cuda
            except:
                self.cuda_version = "Unknown"


@dataclass
class CPUInfo:
    """CPUä¿¡æ¯"""
    physical_cores: int
    logical_cores: int
    cpu_model: str
    cpu_freq_mhz: Optional[float] = None

    def __post_init__(self):
        if self.cpu_freq_mhz is None:
            try:
                freq = psutil.cpu_freq()
                self.cpu_freq_mhz = freq.max if freq else None
            except:
                self.cpu_freq_mhz = None


@dataclass
class RAMInfo:
    """å†…å­˜ä¿¡æ¯"""
    total_gb: float
    available_gb: float
    percent_used: float

    @property
    def is_sufficient(self) -> bool:
        """æ˜¯å¦æœ‰è¶³å¤Ÿå†…å­˜ï¼ˆå»ºè®®è‡³å°‘6GBå¯ç”¨ï¼Œç†æƒ³8GB+ï¼‰"""
        # åŸºäºå®æµ‹: 3GBå³å¯è·å¾—17.2%æå‡ï¼Œè®¾ç½®6GBä¸ºå®‰å…¨é˜ˆå€¼
        return self.available_gb >= 6.0


@dataclass
class HardwareInfo:
    """å®Œæ•´ç¡¬ä»¶ä¿¡æ¯"""
    gpu: GPUInfo
    cpu: CPUInfo
    ram: RAMInfo
    platform: str
    python_version: str


def detect_gpu() -> GPUInfo:
    """æ£€æµ‹GPUä¿¡æ¯"""
    if not torch.cuda.is_available():
        logger.info("CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
        return GPUInfo(
            available=False,
            device_name="CPU",
            vram_total_gb=0.0,
            vram_available_gb=0.0,
            device_count=0
        )

    try:
        device_count = torch.cuda.device_count()
        device_name = torch.cuda.get_device_name(0)
        props = torch.cuda.get_device_properties(0)
        vram_total_gb = props.total_memory / 1024**3

        # è®¡ç®—å¯ç”¨æ˜¾å­˜
        torch.cuda.empty_cache()
        vram_allocated = torch.cuda.memory_allocated(0) / 1024**3
        vram_available_gb = vram_total_gb - vram_allocated

        logger.info(f"æ£€æµ‹åˆ°GPU: {device_name} ({vram_total_gb:.1f}GB VRAM)")

        return GPUInfo(
            available=True,
            device_name=device_name,
            vram_total_gb=vram_total_gb,
            vram_available_gb=vram_available_gb,
            device_count=device_count
        )

    except Exception as e:
        logger.warning(f"GPUæ£€æµ‹å¤±è´¥: {e}")
        return GPUInfo(
            available=False,
            device_name="CPU",
            vram_total_gb=0.0,
            vram_available_gb=0.0,
            device_count=0
        )


def detect_cpu() -> CPUInfo:
    """æ£€æµ‹CPUä¿¡æ¯"""
    try:
        physical_cores = psutil.cpu_count(logical=False) or 1
        logical_cores = psutil.cpu_count(logical=True) or 1

        # è·å–CPUå‹å·
        cpu_model = platform.processor()
        if not cpu_model or cpu_model.strip() == "":
            # å¤‡ç”¨æ–¹æ³•
            import subprocess
            try:
                if platform.system() == "Windows":
                    result = subprocess.run(
                        ["wmic", "cpu", "get", "name"],
                        capture_output=True,
                        text=True
                    )
                    lines = result.stdout.strip().split('\n')
                    cpu_model = lines[1].strip() if len(lines) > 1 else "Unknown CPU"
                elif platform.system() == "Linux":
                    with open('/proc/cpuinfo', 'r') as f:
                        for line in f:
                            if 'model name' in line:
                                cpu_model = line.split(':')[1].strip()
                                break
                else:
                    cpu_model = "Unknown CPU"
            except:
                cpu_model = "Unknown CPU"

        logger.info(f"æ£€æµ‹åˆ°CPU: {physical_cores}æ ¸ ({logical_cores}çº¿ç¨‹)")

        return CPUInfo(
            physical_cores=physical_cores,
            logical_cores=logical_cores,
            cpu_model=cpu_model
        )

    except Exception as e:
        logger.warning(f"CPUæ£€æµ‹å¤±è´¥: {e}")
        return CPUInfo(
            physical_cores=1,
            logical_cores=1,
            cpu_model="Unknown CPU"
        )


def detect_ram() -> RAMInfo:
    """æ£€æµ‹å†…å­˜ä¿¡æ¯"""
    try:
        mem = psutil.virtual_memory()
        total_gb = mem.total / 1024**3
        available_gb = mem.available / 1024**3
        percent_used = mem.percent

        logger.info(f"æ£€æµ‹åˆ°å†…å­˜: {total_gb:.1f}GB æ€»é‡, {available_gb:.1f}GB å¯ç”¨ ({100-percent_used:.1f}% ç©ºé—²)")

        return RAMInfo(
            total_gb=total_gb,
            available_gb=available_gb,
            percent_used=percent_used
        )

    except Exception as e:
        logger.warning(f"å†…å­˜æ£€æµ‹å¤±è´¥: {e}")
        return RAMInfo(
            total_gb=0.0,
            available_gb=0.0,
            percent_used=100.0
        )


def detect_hardware() -> HardwareInfo:
    """
    æ£€æµ‹å®Œæ•´ç¡¬ä»¶ä¿¡æ¯

    Returns:
        HardwareInfo: åŒ…å«GPUã€CPUã€å†…å­˜ç­‰å®Œæ•´ç¡¬ä»¶ä¿¡æ¯

    Example:
        >>> hw = detect_hardware()
        >>> print(f"GPU: {hw.gpu.device_name}, VRAM: {hw.gpu.vram_total_gb:.1f}GB")
        >>> print(f"CPU: {hw.cpu.physical_cores}æ ¸")
        >>> print(f"RAM: {hw.ram.total_gb:.1f}GB")
    """
    logger.info("="*70)
    logger.info("æ­£åœ¨æ£€æµ‹ç¡¬ä»¶é…ç½®...")
    logger.info("="*70)

    gpu = detect_gpu()
    cpu = detect_cpu()
    ram = detect_ram()

    hw_info = HardwareInfo(
        gpu=gpu,
        cpu=cpu,
        ram=ram,
        platform=platform.system(),
        python_version=platform.python_version()
    )

    logger.info("="*70)
    logger.info("ç¡¬ä»¶æ£€æµ‹å®Œæˆ")
    logger.info("="*70)

    return hw_info


def print_hardware_summary(hw: HardwareInfo):
    """
    æ‰“å°ç¡¬ä»¶ä¿¡æ¯æ‘˜è¦

    Args:
        hw: HardwareInfoå¯¹è±¡
    """
    print("\n" + "="*70)
    print("ğŸ” ç¡¬ä»¶é…ç½®æ£€æµ‹ç»“æœ")
    print("="*70)

    # GPUä¿¡æ¯
    if hw.gpu.available:
        print(f"âœ“ GPU: {hw.gpu.device_name}")
        print(f"  - VRAM: {hw.gpu.vram_total_gb:.1f}GB (å¯ç”¨: {hw.gpu.vram_available_gb:.1f}GB)")
        print(f"  - CUDA: {hw.gpu.cuda_version}")
        if hw.gpu.device_count > 1:
            print(f"  - è®¾å¤‡æ•°: {hw.gpu.device_count}ä¸ªGPU")
    else:
        print(f"âœ— GPU: ä¸å¯ç”¨")
        print(f"  - æ¨¡å¼: CPUæ¨ç†")

    # CPUä¿¡æ¯
    print(f"âœ“ CPU: {hw.cpu.physical_cores}æ ¸å¿ƒ ({hw.cpu.logical_cores}çº¿ç¨‹)")
    if hw.cpu.cpu_freq_mhz:
        print(f"  - é¢‘ç‡: {hw.cpu.cpu_freq_mhz:.0f}MHz")
    if hw.cpu.cpu_model and hw.cpu.cpu_model != "Unknown CPU":
        model_short = hw.cpu.cpu_model[:50] + "..." if len(hw.cpu.cpu_model) > 50 else hw.cpu.cpu_model
        print(f"  - å‹å·: {model_short}")

    # å†…å­˜ä¿¡æ¯
    print(f"âœ“ RAM: {hw.ram.total_gb:.1f}GB æ€»é‡")
    print(f"  - å¯ç”¨: {hw.ram.available_gb:.1f}GB ({100-hw.ram.percent_used:.1f}% ç©ºé—²)")
    if not hw.ram.is_sufficient:
        print(f"  âš ï¸  è­¦å‘Š: å¯ç”¨å†…å­˜ä¸è¶³8GBï¼Œå¯èƒ½å½±å“æ€§èƒ½")

    # å¹³å°ä¿¡æ¯
    print(f"âœ“ å¹³å°: {hw.platform}")
    print(f"âœ“ Python: {hw.python_version}")

    print("="*70 + "\n")


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO, format='%(message)s')

    print("\næµ‹è¯•ç¡¬ä»¶æ£€æµ‹æ¨¡å—...")
    print("="*70)

    hw = detect_hardware()
    print_hardware_summary(hw)

    # éªŒè¯
    print("\néªŒæ”¶æ ‡å‡†æ£€æŸ¥:")
    print(f"âœ“ GPUå¯ç”¨: {hw.gpu.available}")
    print(f"âœ“ VRAM: {hw.gpu.vram_total_gb:.1f}GB")
    print(f"âœ“ CPUæ ¸å¿ƒ: {hw.cpu.physical_cores}")
    print(f"âœ“ å†…å­˜: {hw.ram.total_gb:.1f}GB")

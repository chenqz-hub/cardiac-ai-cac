"""
NB10 AI-CAC å®‰å…¨ç›‘æ§æ¨¡å—
Safety Monitor Module

åŠŸèƒ½:
1. å†…å­˜ç›‘æ§ä¸OOMä¿æŠ¤
2. GPUæ˜¾å­˜ç›‘æ§
3. è‡ªåŠ¨é™çº§æœºåˆ¶
4. å¼‚å¸¸æ£€æµ‹ä¸æ¢å¤

ä½œè€…: NB10 Team + Claude Code
æ—¥æœŸ: 2025-10-14
"""

import psutil
import torch
import logging
from typing import Optional, Dict, Any, Tuple
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)


class SafetyLevel(Enum):
    """å®‰å…¨ç­‰çº§"""
    SAFE = "safe"           # å®‰å…¨ï¼šèµ„æºå……è¶³
    WARNING = "warning"     # è­¦å‘Šï¼šæ¥è¿‘é˜ˆå€¼
    CRITICAL = "critical"   # å±é™©ï¼šéœ€è¦é™çº§
    EMERGENCY = "emergency" # ç´§æ€¥ï¼šç«‹å³åœæ­¢


@dataclass
class ResourceStatus:
    """èµ„æºçŠ¶æ€"""
    # RAMçŠ¶æ€
    ram_total_gb: float
    ram_available_gb: float
    ram_percent_used: float
    ram_level: SafetyLevel

    # GPU VRAMçŠ¶æ€
    vram_total_gb: float
    vram_allocated_gb: float
    vram_reserved_gb: float
    vram_free_gb: float
    vram_percent_used: float
    vram_level: SafetyLevel

    # æ•´ä½“å®‰å…¨ç­‰çº§
    overall_level: SafetyLevel

    # å»ºè®®æ“ä½œ
    action_needed: str
    details: str


class SafetyMonitor:
    """
    å®‰å…¨ç›‘æ§å™¨

    èŒè´£:
    1. å®æ—¶ç›‘æ§RAMå’ŒVRAMä½¿ç”¨æƒ…å†µ
    2. æ£€æµ‹OOMé£é™©
    3. å»ºè®®é™çº§æ“ä½œ
    """

    def __init__(
        self,
        # RAMé˜ˆå€¼ï¼ˆå¯ç”¨å†…å­˜ç™¾åˆ†æ¯”ï¼‰
        ram_warning_threshold: float = 20.0,    # å¯ç”¨<20%è­¦å‘Š
        ram_critical_threshold: float = 10.0,   # å¯ç”¨<10%å±é™©
        ram_emergency_threshold: float = 5.0,   # å¯ç”¨<5%ç´§æ€¥

        # VRAMé˜ˆå€¼ï¼ˆå·²ç”¨å†…å­˜ç™¾åˆ†æ¯”ï¼‰
        vram_warning_threshold: float = 80.0,   # å·²ç”¨>80%è­¦å‘Š
        vram_critical_threshold: float = 90.0,  # å·²ç”¨>90%å±é™©
        vram_emergency_threshold: float = 95.0, # å·²ç”¨>95%ç´§æ€¥

        # æ˜¯å¦å¯ç”¨è‡ªåŠ¨é™çº§
        enable_auto_downgrade: bool = True,
    ):
        """
        åˆå§‹åŒ–å®‰å…¨ç›‘æ§å™¨

        Args:
            ram_warning_threshold: RAMè­¦å‘Šé˜ˆå€¼ï¼ˆå¯ç”¨ç™¾åˆ†æ¯”ï¼‰
            ram_critical_threshold: RAMå±é™©é˜ˆå€¼
            ram_emergency_threshold: RAMç´§æ€¥é˜ˆå€¼
            vram_warning_threshold: VRAMè­¦å‘Šé˜ˆå€¼ï¼ˆå·²ç”¨ç™¾åˆ†æ¯”ï¼‰
            vram_critical_threshold: VRAMå±é™©é˜ˆå€¼
            vram_emergency_threshold: VRAMç´§æ€¥é˜ˆå€¼
            enable_auto_downgrade: æ˜¯å¦å¯ç”¨è‡ªåŠ¨é™çº§
        """
        self.ram_warning = ram_warning_threshold
        self.ram_critical = ram_critical_threshold
        self.ram_emergency = ram_emergency_threshold

        self.vram_warning = vram_warning_threshold
        self.vram_critical = vram_critical_threshold
        self.vram_emergency = vram_emergency_threshold

        self.enable_auto_downgrade = enable_auto_downgrade

        # æ£€æŸ¥CUDAå¯ç”¨æ€§
        self.cuda_available = torch.cuda.is_available()

        logger.info(f"SafetyMonitor initialized")
        logger.info(f"  RAM thresholds: {self.ram_warning}%/{self.ram_critical}%/{self.ram_emergency}%")
        logger.info(f"  VRAM thresholds: {self.vram_warning}%/{self.vram_critical}%/{self.vram_emergency}%")
        logger.info(f"  Auto-downgrade: {enable_auto_downgrade}")

    def check_ram_status(self) -> Tuple[float, float, float, SafetyLevel]:
        """
        æ£€æŸ¥RAMçŠ¶æ€

        Returns:
            (total_gb, available_gb, percent_available, level)
        """
        mem = psutil.virtual_memory()
        total_gb = mem.total / (1024 ** 3)
        available_gb = mem.available / (1024 ** 3)
        percent_available = (mem.available / mem.total) * 100

        # åˆ¤æ–­å®‰å…¨ç­‰çº§
        if percent_available < self.ram_emergency:
            level = SafetyLevel.EMERGENCY
        elif percent_available < self.ram_critical:
            level = SafetyLevel.CRITICAL
        elif percent_available < self.ram_warning:
            level = SafetyLevel.WARNING
        else:
            level = SafetyLevel.SAFE

        return total_gb, available_gb, percent_available, level

    def check_vram_status(self) -> Tuple[float, float, float, float, float, SafetyLevel]:
        """
        æ£€æŸ¥GPU VRAMçŠ¶æ€

        Returns:
            (total_gb, allocated_gb, reserved_gb, free_gb, percent_used, level)
        """
        if not self.cuda_available:
            return 0.0, 0.0, 0.0, 0.0, 0.0, SafetyLevel.SAFE

        # è·å–VRAMä¿¡æ¯
        total_bytes = torch.cuda.get_device_properties(0).total_memory
        allocated_bytes = torch.cuda.memory_allocated(0)
        reserved_bytes = torch.cuda.memory_reserved(0)

        total_gb = total_bytes / (1024 ** 3)
        allocated_gb = allocated_bytes / (1024 ** 3)
        reserved_gb = reserved_bytes / (1024 ** 3)
        free_gb = (total_bytes - reserved_bytes) / (1024 ** 3)
        percent_used = (reserved_bytes / total_bytes) * 100

        # åˆ¤æ–­å®‰å…¨ç­‰çº§
        if percent_used > self.vram_emergency:
            level = SafetyLevel.EMERGENCY
        elif percent_used > self.vram_critical:
            level = SafetyLevel.CRITICAL
        elif percent_used > self.vram_warning:
            level = SafetyLevel.WARNING
        else:
            level = SafetyLevel.SAFE

        return total_gb, allocated_gb, reserved_gb, free_gb, percent_used, level

    def check_status(self) -> ResourceStatus:
        """
        æ£€æŸ¥æ•´ä½“èµ„æºçŠ¶æ€

        Returns:
            ResourceStatuså¯¹è±¡
        """
        # æ£€æŸ¥RAM
        ram_total, ram_avail, ram_percent_avail, ram_level = self.check_ram_status()
        ram_percent_used = 100 - ram_percent_avail

        # æ£€æŸ¥VRAM
        vram_total, vram_alloc, vram_reserved, vram_free, vram_percent_used, vram_level = self.check_vram_status()

        # ç¡®å®šæ•´ä½“å®‰å…¨ç­‰çº§ï¼ˆå–æœ€å±é™©çš„ï¼‰
        levels = [ram_level, vram_level]
        if SafetyLevel.EMERGENCY in levels:
            overall = SafetyLevel.EMERGENCY
        elif SafetyLevel.CRITICAL in levels:
            overall = SafetyLevel.CRITICAL
        elif SafetyLevel.WARNING in levels:
            overall = SafetyLevel.WARNING
        else:
            overall = SafetyLevel.SAFE

        # ç¡®å®šå»ºè®®æ“ä½œ
        action, details = self._determine_action(ram_level, vram_level, ram_avail, vram_free)

        return ResourceStatus(
            ram_total_gb=ram_total,
            ram_available_gb=ram_avail,
            ram_percent_used=ram_percent_used,
            ram_level=ram_level,

            vram_total_gb=vram_total,
            vram_allocated_gb=vram_alloc,
            vram_reserved_gb=vram_reserved,
            vram_free_gb=vram_free,
            vram_percent_used=vram_percent_used,
            vram_level=vram_level,

            overall_level=overall,
            action_needed=action,
            details=details
        )

    def _determine_action(
        self,
        ram_level: SafetyLevel,
        vram_level: SafetyLevel,
        ram_avail: float,
        vram_free: float
    ) -> Tuple[str, str]:
        """
        ç¡®å®šå»ºè®®æ“ä½œ

        Returns:
            (action, details)
        """
        # ç´§æ€¥æƒ…å†µï¼šç«‹å³åœæ­¢
        if ram_level == SafetyLevel.EMERGENCY or vram_level == SafetyLevel.EMERGENCY:
            return "STOP", f"èµ„æºä¸¥é‡ä¸è¶³ (RAM: {ram_avail:.1f}GB, VRAM: {vram_free:.1f}GB)ï¼Œå»ºè®®ç«‹å³åœæ­¢"

        # å±é™©æƒ…å†µï¼šé™çº§é…ç½®
        if ram_level == SafetyLevel.CRITICAL or vram_level == SafetyLevel.CRITICAL:
            details = []
            if ram_level == SafetyLevel.CRITICAL:
                details.append(f"RAMä¸è¶³({ram_avail:.1f}GB)")
            if vram_level == SafetyLevel.CRITICAL:
                details.append(f"VRAMä¸è¶³({vram_free:.1f}GB)")
            return "DOWNGRADE", f"{', '.join(details)}ï¼Œå»ºè®®é™çº§é…ç½®"

        # è­¦å‘Šæƒ…å†µï¼šç›‘æ§
        if ram_level == SafetyLevel.WARNING or vram_level == SafetyLevel.WARNING:
            return "MONITOR", f"èµ„æºæ¥è¿‘é˜ˆå€¼ (RAM: {ram_avail:.1f}GB, VRAM: {vram_free:.1f}GB)ï¼Œç»§ç»­ç›‘æ§"

        # å®‰å…¨
        return "CONTINUE", f"èµ„æºå……è¶³ (RAM: {ram_avail:.1f}GB, VRAM: {vram_free:.1f}GB)"

    def log_status(self, status: ResourceStatus, prefix: str = ""):
        """
        è®°å½•èµ„æºçŠ¶æ€åˆ°æ—¥å¿—

        Args:
            status: èµ„æºçŠ¶æ€
            prefix: æ—¥å¿—å‰ç¼€
        """
        level_emoji = {
            SafetyLevel.SAFE: "âœ…",
            SafetyLevel.WARNING: "âš ï¸",
            SafetyLevel.CRITICAL: "ğŸ”´",
            SafetyLevel.EMERGENCY: "ğŸš¨"
        }

        emoji = level_emoji.get(status.overall_level, "â“")

        logger.info(f"{prefix}{emoji} Resource Status: {status.overall_level.value.upper()}")
        logger.info(f"{prefix}  RAM: {status.ram_available_gb:.1f}GB available ({100-status.ram_percent_used:.1f}%) - {status.ram_level.value}")
        logger.info(f"{prefix}  VRAM: {status.vram_free_gb:.1f}GB free ({100-status.vram_percent_used:.1f}%) - {status.vram_level.value}")
        logger.info(f"{prefix}  Action: {status.action_needed} - {status.details}")

    def should_downgrade(self, status: ResourceStatus) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦é™çº§

        Args:
            status: èµ„æºçŠ¶æ€

        Returns:
            True iféœ€è¦é™çº§
        """
        if not self.enable_auto_downgrade:
            return False

        return status.action_needed in ["DOWNGRADE", "STOP"]

    def suggest_downgrade_profile(self, current_num_workers: int) -> Dict[str, Any]:
        """
        å»ºè®®é™çº§é…ç½®

        Args:
            current_num_workers: å½“å‰num_workers

        Returns:
            é™çº§åçš„é…ç½®å»ºè®®
        """
        status = self.check_status()

        # ç´§æ€¥æƒ…å†µï¼šæœ€å°é…ç½®
        if status.overall_level == SafetyLevel.EMERGENCY:
            return {
                "num_workers": 0,
                "pin_memory": False,
                "prefetch_factor": None,
                "reason": "EMERGENCY: èµ„æºä¸¥é‡ä¸è¶³ï¼Œåˆ‡æ¢åˆ°æœ€å°é…ç½®"
            }

        # å±é™©æƒ…å†µï¼šé™ä½num_workers
        if status.overall_level == SafetyLevel.CRITICAL:
            new_workers = max(0, current_num_workers - 1)
            return {
                "num_workers": new_workers,
                "pin_memory": True if new_workers > 0 else False,
                "prefetch_factor": 2 if new_workers > 0 else None,
                "reason": f"CRITICAL: é™ä½num_workers {current_num_workers} â†’ {new_workers}"
            }

        # æ— éœ€é™çº§
        return {
            "num_workers": current_num_workers,
            "pin_memory": True,
            "prefetch_factor": 2,
            "reason": "èµ„æºå……è¶³ï¼Œä¿æŒå½“å‰é…ç½®"
        }

    def clear_gpu_cache(self):
        """æ¸…ç†GPUç¼“å­˜"""
        if self.cuda_available:
            torch.cuda.empty_cache()
            logger.info("GPU cache cleared")


# å…¨å±€å•ä¾‹
_monitor_instance: Optional[SafetyMonitor] = None


def get_monitor(
    ram_warning: float = 20.0,
    ram_critical: float = 10.0,
    ram_emergency: float = 5.0,
    vram_warning: float = 80.0,
    vram_critical: float = 90.0,
    vram_emergency: float = 95.0,
    enable_auto_downgrade: bool = True,
) -> SafetyMonitor:
    """
    è·å–å…¨å±€SafetyMonitorå®ä¾‹

    Returns:
        SafetyMonitorå•ä¾‹
    """
    global _monitor_instance

    if _monitor_instance is None:
        _monitor_instance = SafetyMonitor(
            ram_warning_threshold=ram_warning,
            ram_critical_threshold=ram_critical,
            ram_emergency_threshold=ram_emergency,
            vram_warning_threshold=vram_warning,
            vram_critical_threshold=vram_critical,
            vram_emergency_threshold=vram_emergency,
            enable_auto_downgrade=enable_auto_downgrade,
        )

    return _monitor_instance


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')

    print("=" * 70)
    print("NB10 Safety Monitor æµ‹è¯•")
    print("=" * 70)

    # åˆ›å»ºç›‘æ§å™¨
    monitor = get_monitor()

    # æ£€æŸ¥çŠ¶æ€
    status = monitor.check_status()

    # æ‰“å°çŠ¶æ€
    print(f"\nå½“å‰èµ„æºçŠ¶æ€:")
    print(f"  RAM: {status.ram_available_gb:.2f}GB å¯ç”¨ / {status.ram_total_gb:.2f}GB æ€»é‡ ({100-status.ram_percent_used:.1f}%)")
    print(f"  VRAM: {status.vram_free_gb:.2f}GB å¯ç”¨ / {status.vram_total_gb:.2f}GB æ€»é‡ ({100-status.vram_percent_used:.1f}%)")
    print(f"\nå®‰å…¨ç­‰çº§:")
    print(f"  RAM: {status.ram_level.value}")
    print(f"  VRAM: {status.vram_level.value}")
    print(f"  æ•´ä½“: {status.overall_level.value}")
    print(f"\nå»ºè®®æ“ä½œ: {status.action_needed}")
    print(f"  è¯¦æƒ…: {status.details}")

    # æµ‹è¯•é™çº§å»ºè®®
    print(f"\né™çº§å»ºè®®æµ‹è¯• (å½“å‰num_workers=2):")
    suggestion = monitor.suggest_downgrade_profile(current_num_workers=2)
    print(f"  å»ºè®®num_workers: {suggestion['num_workers']}")
    print(f"  å»ºè®®pin_memory: {suggestion['pin_memory']}")
    print(f"  åŸå› : {suggestion['reason']}")

    # è®°å½•åˆ°æ—¥å¿—
    print("\næ—¥å¿—è¾“å‡º:")
    monitor.log_status(status, prefix="  ")

    print("\n" + "=" * 70)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("=" * 70)

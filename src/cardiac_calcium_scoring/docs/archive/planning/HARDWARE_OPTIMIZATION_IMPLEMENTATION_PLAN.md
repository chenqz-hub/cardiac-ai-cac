# ç¡¬ä»¶è‡ªé€‚åº”ä¼˜åŒ– - å®æ–½è®¡åˆ’
# Hardware Adaptive Optimization - Implementation Plan

**ç‰ˆæœ¬**: 1.0.0
**åˆ›å»ºæ—¥æœŸ**: 2025-10-14
**ç›®æ ‡ç‰ˆæœ¬**: NB10 v1.1.0
**é¢„æœŸå®Œæˆ**: 6å‘¨ï¼ˆWeek 3-4 in Hospital Deployment Roadmapï¼‰

---

## ğŸ“‹ å¿«é€Ÿæ¦‚è§ˆ

åŸºäº [HARDWARE_ADAPTIVE_OPTIMIZATION_DESIGN.md](HARDWARE_ADAPTIVE_OPTIMIZATION_DESIGN.md) çš„å®Œæ•´è®¾è®¡ï¼Œæœ¬æ–‡æ¡£æä¾›ä¸€ä¸ª**å¯ç«‹å³æ‰§è¡Œ**çš„å®æ–½è®¡åˆ’ã€‚

### æ ¸å¿ƒç›®æ ‡

âœ… åœ¨RTX 2060 (6GB)ä¸Šå®ç° **20-30%æ€§èƒ½æå‡**
âœ… é›¶é…ç½®ï¼Œè‡ªåŠ¨æ£€æµ‹ç¡¬ä»¶å¹¶ä¼˜åŒ–
âœ… ä¿æŒåŒ»ç–—çº§ç¨³å®šæ€§å’Œç»“æœä¸€è‡´æ€§

### ä¼˜å…ˆçº§æ’åº

**Phase 1 (Week 1)**: æ ¸å¿ƒä¼˜åŒ– - ç«‹å³å¯è§çš„æ€§èƒ½æå‡
**Phase 2 (Week 2)**: å®‰å…¨ç›‘æ§ - ç¡®ä¿ç¨³å®šæ€§
**Phase 3 (Week 3-4)**: é«˜çº§åŠŸèƒ½ - å¯é€‰

---

## ğŸš€ Phase 1: æ ¸å¿ƒä¼˜åŒ–ï¼ˆWeek 1ï¼‰- ç«‹å³å®æ–½

### ä»»åŠ¡1.1: ç¡¬ä»¶æ£€æµ‹æ¨¡å— (Day 1-2)

**ç›®æ ‡**: å®ç°åŸºç¡€ç¡¬ä»¶æ£€æµ‹

**æ–°å»ºæ–‡ä»¶**: `core/hardware_profiler.py`

```python
"""ç¡¬ä»¶æ£€æµ‹æ¨¡å—"""
import torch
import psutil
import platform

class GPUInfo:
    def __init__(self):
        self.available = torch.cuda.is_available()
        if self.available:
            self.device_name = torch.cuda.get_device_name(0)
            self.vram_total_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
            self.vram_available_gb = self.vram_total_gb  # ç®€åŒ–ç‰ˆæœ¬
        else:
            self.device_name = "CPU"
            self.vram_total_gb = 0
            self.vram_available_gb = 0

class CPUInfo:
    def __init__(self):
        self.physical_cores = psutil.cpu_count(logical=False)
        self.logical_cores = psutil.cpu_count(logical=True)
        self.cpu_model = platform.processor()

class RAMInfo:
    def __init__(self):
        mem = psutil.virtual_memory()
        self.total_gb = mem.total / 1024**3
        self.available_gb = mem.available / 1024**3

def detect_hardware():
    """æ£€æµ‹ç¡¬ä»¶ä¿¡æ¯"""
    return {
        'gpu': GPUInfo(),
        'cpu': CPUInfo(),
        'ram': RAMInfo()
    }
```

**éªŒæ”¶æ ‡å‡†**:
```bash
python -c "from core.hardware_profiler import detect_hardware; hw=detect_hardware(); print(f'GPU: {hw[\"gpu\"].device_name}, VRAM: {hw[\"gpu\"].vram_total_gb:.1f}GB')"
# è¾“å‡º: GPU: NVIDIA GeForce RTX 2060, VRAM: 6.0GB
```

---

### ä»»åŠ¡1.2: é…ç½®æ¡£ä½ç³»ç»Ÿ (Day 2-3)

**ç›®æ ‡**: å®šä¹‰5æ¡£é…ç½®å¹¶å®ç°è‡ªåŠ¨é€‰æ‹©

**æ–°å»ºæ–‡ä»¶**: `core/performance_profiles.py`

```python
"""æ€§èƒ½é…ç½®æ¡£ä½"""
from enum import Enum
from dataclasses import dataclass

class ProfileTier(Enum):
    MINIMAL = 1
    STANDARD = 2
    PERFORMANCE = 3
    PROFESSIONAL = 4
    ENTERPRISE = 5

@dataclass
class PerformanceProfile:
    tier: ProfileTier
    num_workers: int
    pin_memory: bool
    slice_batch_size: int
    clear_cache_interval: int

# é¢„å®šä¹‰é…ç½®
PROFILES = {
    ProfileTier.MINIMAL: PerformanceProfile(
        tier=ProfileTier.MINIMAL,
        num_workers=0,
        pin_memory=False,
        slice_batch_size=2,
        clear_cache_interval=1
    ),
    ProfileTier.STANDARD: PerformanceProfile(
        tier=ProfileTier.STANDARD,
        num_workers=2,          # â† å…³é”®ä¼˜åŒ–
        pin_memory=True,        # â† å…³é”®ä¼˜åŒ–
        slice_batch_size=4,
        clear_cache_interval=1
    ),
    ProfileTier.PERFORMANCE: PerformanceProfile(
        tier=ProfileTier.PERFORMANCE,
        num_workers=4,
        pin_memory=True,
        slice_batch_size=6,
        clear_cache_interval=3
    )
}

def select_profile(hw_info):
    """æ ¹æ®ç¡¬ä»¶ä¿¡æ¯é€‰æ‹©æœ€ä¼˜é…ç½®"""
    gpu = hw_info['gpu']
    ram = hw_info['ram']

    if not gpu.available:
        return PROFILES[ProfileTier.MINIMAL]

    if gpu.vram_total_gb >= 12:
        return PROFILES[ProfileTier.PERFORMANCE]
    elif gpu.vram_total_gb >= 6:
        return PROFILES[ProfileTier.STANDARD]
    else:
        return PROFILES[ProfileTier.MINIMAL]
```

---

### ä»»åŠ¡1.3: ä¿®æ”¹æ¨ç†æ ¸å¿ƒ (Day 3-4)

**ç›®æ ‡**: åº”ç”¨ä¼˜åŒ–é…ç½®åˆ°å®é™…æ¨ç†

**ä¿®æ”¹æ–‡ä»¶**: `core/ai_cac_inference_lib.py`

**å…³é”®ä¿®æ”¹**:

```python
# Line ~136: DataLoaderé…ç½®
from core.performance_profiles import select_profile
from core.hardware_profiler import detect_hardware

# åœ¨å‡½æ•°å¼€å§‹å¤„æ£€æµ‹ç¡¬ä»¶
hw_info = detect_hardware()
profile = select_profile(hw_info)

print(f"âœ“ æ£€æµ‹åˆ°ç¡¬ä»¶: {hw_info['gpu'].device_name}")
print(f"âœ“ ä½¿ç”¨é…ç½®æ¡£ä½: {profile.tier.name}")
print(f"  - num_workers: {profile.num_workers}")
print(f"  - pin_memory: {profile.pin_memory}")

# åŸä»£ç :
# dataloader = DataLoader(dataset, batch_size=1, shuffle=False,
#                        num_workers=0, pin_memory=False)

# ä¿®æ”¹ä¸º:
dataloader = DataLoader(
    dataset,
    batch_size=1,
    shuffle=False,
    num_workers=profile.num_workers,      # â† åŠ¨æ€é…ç½®
    pin_memory=profile.pin_memory,        # â† åŠ¨æ€é…ç½®
    prefetch_factor=2 if profile.num_workers > 0 else None
)
```

**é¢„æœŸæ•ˆæœ**:
- RTX 2060: ä»35-40ç§’/æ‚£è€… â†’ 28-32ç§’/æ‚£è€… (**â†“20-25%**)
- æ— ç»“æœå·®å¼‚ï¼ˆå·²é€šè¿‡PilotéªŒè¯ï¼‰

---

### ä»»åŠ¡1.4: CLIé›†æˆ (Day 4-5)

**ç›®æ ‡**: åœ¨å¯åŠ¨æ—¶æ˜¾ç¤ºç¡¬ä»¶æ£€æµ‹ç»“æœ

**ä¿®æ”¹æ–‡ä»¶**: `cli/run_nb10.py`

```python
def main():
    # ... ç°æœ‰ä»£ç  ...

    # æ·»åŠ ç¡¬ä»¶æ£€æµ‹æ˜¾ç¤º
    print("="*70)
    print("ğŸ” æ­£åœ¨æ£€æµ‹ç¡¬ä»¶é…ç½®...")
    print("="*70)

    from core.hardware_profiler import detect_hardware
    from core.performance_profiles import select_profile

    hw_info = detect_hardware()
    profile = select_profile(hw_info)

    print(f"âœ“ GPU: {hw_info['gpu'].device_name} "
          f"({hw_info['gpu'].vram_total_gb:.1f}GB)")
    print(f"âœ“ RAM: {hw_info['ram'].total_gb:.1f}GB")
    print(f"âœ“ CPU: {hw_info['cpu'].physical_cores}æ ¸")
    print(f"\næ¨èé…ç½®æ¡£ä½: {profile.tier.name}")
    print(f"é¢„è®¡æ€§èƒ½æå‡: 20-30%")
    print("="*70)
    print()

    # ... ç»§ç»­ç°æœ‰æµç¨‹ ...
```

---

## ğŸ›¡ï¸ Phase 2: å®‰å…¨ç›‘æ§ï¼ˆWeek 2ï¼‰

### ä»»åŠ¡2.1: OOMä¿æŠ¤ (Day 1-2)

**æ–°å»ºæ–‡ä»¶**: `core/safety_monitor.py`

```python
"""å®‰å…¨ç›‘æ§æ¨¡å—"""
import torch
import logging

logger = logging.getLogger(__name__)

class OOMProtector:
    """OOMä¿æŠ¤å™¨"""
    def __init__(self, profile):
        self.profile = profile
        self.oom_count = 0

    def check_memory_before_inference(self):
        """æ¨ç†å‰æ£€æŸ¥GPUå†…å­˜"""
        if not torch.cuda.is_available():
            return True

        # è·å–å¯ç”¨æ˜¾å­˜
        available_gb = (torch.cuda.get_device_properties(0).total_memory -
                       torch.cuda.memory_allocated(0)) / 1024**3

        # ä¼°ç®—éœ€è¦çš„æ˜¾å­˜ (ç»éªŒå€¼: slice_batch_size * 0.8GB)
        required_gb = self.profile.slice_batch_size * 0.8

        if available_gb < required_gb * 1.2:  # éœ€è¦20%å®‰å…¨è¾¹é™…
            logger.warning(f"âš ï¸ å¯ç”¨æ˜¾å­˜ä¸è¶³: {available_gb:.1f}GB < {required_gb*1.2:.1f}GB")
            logger.warning("  å»ºè®®: é™ä½batch sizeæˆ–åˆ‡æ¢åˆ°ç¨³å®šæ¨¡å¼")
            return False

        return True

    def handle_oom(self):
        """å¤„ç†OOMå¼‚å¸¸"""
        self.oom_count += 1

        if self.oom_count >= 3:
            logger.error("âŒ è¿ç»­3æ¬¡OOMï¼Œå»ºè®®åˆ‡æ¢åˆ°CPUæ¨¡å¼")
            return False

        # è‡ªåŠ¨é™çº§
        old_size = self.profile.slice_batch_size
        self.profile.slice_batch_size = max(2, old_size - 2)

        logger.warning(f"âš ï¸ OOMæ£€æµ‹ï¼Œå·²é™çº§: batch_size {old_size} â†’ {self.profile.slice_batch_size}")
        torch.cuda.empty_cache()

        return True  # å¯ä»¥é‡è¯•
```

**é›†æˆåˆ°æ¨ç†**:

```python
# åœ¨ ai_cac_inference_lib.py ä¸­
from core.safety_monitor import OOMProtector

oom_protector = OOMProtector(profile)

try:
    # æ¨ç†å‰æ£€æŸ¥
    if not oom_protector.check_memory_before_inference():
        logger.warning("å†…å­˜ä¸è¶³è­¦å‘Šï¼Œä½†ç»§ç»­å°è¯•...")

    # æ¨ç†ä»£ç ...

except RuntimeError as e:
    if "out of memory" in str(e).lower():
        if oom_protector.handle_oom():
            # é‡è¯•
            continue
        else:
            raise
```

---

### ä»»åŠ¡2.2: æ€§èƒ½è·Ÿè¸ª (Day 3-4)

**ç›®æ ‡**: ç›‘æ§å®é™…æ€§èƒ½å¹¶ä¸é¢„æœŸå¯¹æ¯”

```python
class PerformanceTracker:
    """æ€§èƒ½è·Ÿè¸ªå™¨"""
    def __init__(self, expected_time_per_patient):
        self.expected_time = expected_time_per_patient
        self.processing_times = []

    def record_time(self, elapsed_time):
        """è®°å½•å¤„ç†æ—¶é—´"""
        self.processing_times.append(elapsed_time)

        # æ¯5ä¸ªpatientæ£€æŸ¥ä¸€æ¬¡
        if len(self.processing_times) % 5 == 0:
            avg_time = sum(self.processing_times[-5:]) / 5

            if avg_time > self.expected_time * 1.5:
                logger.warning("="*60)
                logger.warning("âš ï¸ æ€§èƒ½ä½äºé¢„æœŸ")
                logger.warning(f"  é¢„æœŸ: {self.expected_time:.1f}ç§’/ä¾‹")
                logger.warning(f"  å®é™…: {avg_time:.1f}ç§’/ä¾‹")
                logger.warning("  å»ºè®®: æ£€æŸ¥ç³»ç»Ÿèµ„æºæˆ–åˆ‡æ¢åˆ°ç¨³å®šæ¨¡å¼")
                logger.warning("="*60)
```

---

## ğŸ¯ Phase 3: é«˜çº§åŠŸèƒ½ï¼ˆWeek 3-4, å¯é€‰ï¼‰

### å¯é€‰åŠŸèƒ½åˆ—è¡¨

| åŠŸèƒ½ | ä¼˜å…ˆçº§ | æ€§èƒ½æå‡ | å¤æ‚åº¦ | é£é™© |
|------|--------|----------|--------|------|
| GPUæ¸©åº¦ç›‘æ§ | ä¸­ | 0% | ä½ | ä½ |
| æ··åˆç²¾åº¦æ¨ç†(FP16) | ä½ | 10-15% | ä¸­ | **é«˜** (éœ€éªŒè¯ç²¾åº¦) |
| å¼‚æ­¥æ•°æ®ä¼ è¾“ | ä½ | 5-10% | é«˜ | ä¸­ |
| å¤šGPUæ”¯æŒ | ä½ | 50%+ | å¾ˆé«˜ | ä¸­ |

**å»ºè®®**: v1.1.0ä»…å®æ–½Phase 1-2ï¼Œé«˜çº§åŠŸèƒ½å»¶ååˆ°v1.2.0

---

## âœ… æµ‹è¯•ä¸éªŒè¯

### æµ‹è¯•çŸ©é˜µ

| ç¡¬ä»¶ç¯å¢ƒ | æ¡£ä½ | é¢„æœŸæ—¶é—´ | éªŒæ”¶æ ‡å‡† |
|---------|------|---------|----------|
| RTX 2060 6GB | Standard | 28-32ç§’ | âœ… æå‡20-25% |
| RTX 3060 12GB | Performance | 18-22ç§’ | âœ… æå‡40-45% |
| CPU only | Minimal | 100-150ç§’ | âœ… æ­£å¸¸è¿è¡Œ |

### ä¸€è‡´æ€§éªŒè¯

**å…³é”®**: å¿…é¡»éªŒè¯ä¼˜åŒ–åç»“æœä¸ä¼˜åŒ–å‰å®Œå…¨ä¸€è‡´

```bash
# è¿è¡Œ30ä¾‹Pilotæµ‹è¯•
python cli/run_nb10.py --mode pilot --pilot-limit 30

# å¯¹æ¯”ç»“æœ
python scripts/compare_with_baseline.py \
    --baseline results/baseline_30cases.csv \
    --optimized output/nb10_results_optimized.csv

# é¢„æœŸè¾“å‡º:
# âœ… 30/30ä¾‹å®Œå…¨ä¸€è‡´ (å·®å¼‚0.0000åˆ†)
# âœ… å¹³å‡æ—¶é—´: 35.2ç§’ â†’ 28.5ç§’ (â†“19.0%)
```

---

## ğŸ“¦ äº¤ä»˜æ¸…å•

### Week 1 äº¤ä»˜ç‰©

- [ ] `core/hardware_profiler.py` (ç¡¬ä»¶æ£€æµ‹)
- [ ] `core/performance_profiles.py` (é…ç½®æ¡£ä½)
- [ ] ä¿®æ”¹ `core/ai_cac_inference_lib.py` (åº”ç”¨ä¼˜åŒ–)
- [ ] ä¿®æ”¹ `cli/run_nb10.py` (æ˜¾ç¤ºç¡¬ä»¶ä¿¡æ¯)
- [ ] å•å…ƒæµ‹è¯• `tests/test_hardware_profiler.py`
- [ ] æ€§èƒ½æµ‹è¯•æŠ¥å‘Š (30ä¾‹Pilot)

### Week 2 äº¤ä»˜ç‰©

- [ ] `core/safety_monitor.py` (å®‰å…¨ç›‘æ§)
- [ ] é›†æˆOOMä¿æŠ¤åˆ°æ¨ç†æµç¨‹
- [ ] é›†æˆæ€§èƒ½è·Ÿè¸ªåˆ°æ¨ç†æµç¨‹
- [ ] æ›´æ–°ç”¨æˆ·æ–‡æ¡£
- [ ] å®Œæ•´æµ‹è¯•æŠ¥å‘Š (60ä¾‹éªŒè¯)

---

## ğŸš§ é£é™©ä¸åº”å¯¹

### é£é™©1: Windowså¤šè¿›ç¨‹å…¼å®¹æ€§

**é£é™©**: `num_workers > 0` åœ¨Windowsä¸Šå¯èƒ½ä¸ç¨³å®š

**åº”å¯¹**:
- ä¿å®ˆè®¾ç½® `num_workers=2` (ä¸è¶…è¿‡4)
- æä¾›é™çº§åˆ° `num_workers=0` çš„é€‰é¡¹
- å……åˆ†æµ‹è¯•Windowsç¯å¢ƒ

### é£é™©2: ç»“æœä¸€è‡´æ€§

**é£é™©**: ä¼˜åŒ–å¯èƒ½å½±å“Agatston scoreè®¡ç®—

**åº”å¯¹**:
- **å¼ºåˆ¶è¦æ±‚**: 60ä¾‹Pilotæµ‹è¯•100%ä¸€è‡´
- ä»»ä½•å·®å¼‚ç«‹å³å›é€€ä¿®æ”¹
- å®Œæ•´è®°å½•æ‰€æœ‰æµ‹è¯•ç»“æœ

### é£é™©3: æ€§èƒ½æœªè¾¾é¢„æœŸ

**é£é™©**: å®é™…æå‡< 20%

**åº”å¯¹**:
- é™ä½æ‰¿è¯º: "é¢„æœŸæå‡15-25%"
- åˆ†æç“¶é¢ˆå¹¶è¿­ä»£ä¼˜åŒ–
- æä¾›è¯¦ç»†æ€§èƒ½åˆ†ææŠ¥å‘Š

---

## ğŸ“Š æˆåŠŸæŒ‡æ ‡

### å¿…è¾¾æŒ‡æ ‡ (v1.1.0å‘å¸ƒæ¡ä»¶)

âœ… RTX 2060ä¸Šæ€§èƒ½æå‡ â‰¥ 20%
âœ… 60ä¾‹Pilotæµ‹è¯•ç»“æœ100%ä¸€è‡´
âœ… æ— OOMå´©æºƒï¼ˆè¿ç»­200ä¾‹æµ‹è¯•ï¼‰
âœ… ç”¨æˆ·æ–‡æ¡£å®Œæ•´

### å¯é€‰æŒ‡æ ‡ (v1.2.0ç›®æ ‡)

â­ RTX 3060ä¸Šæ€§èƒ½æå‡ â‰¥ 40%
â­ æ··åˆç²¾åº¦æ¨ç†ï¼ˆç²¾åº¦æŸå¤±<0.1%ï¼‰
â­ å¤šGPUå¹¶è¡Œæ”¯æŒ

---

## ğŸ“… æ—¶é—´çº¿æ€»ç»“

```
Week 1 (Phase 1): æ ¸å¿ƒä¼˜åŒ–
â”œâ”€ Day 1-2: ç¡¬ä»¶æ£€æµ‹æ¨¡å—
â”œâ”€ Day 2-3: é…ç½®æ¡£ä½ç³»ç»Ÿ
â”œâ”€ Day 3-4: ä¿®æ”¹æ¨ç†æ ¸å¿ƒ
â””â”€ Day 4-5: CLIé›†æˆ + åˆæ­¥æµ‹è¯•

Week 2 (Phase 2): å®‰å…¨ç›‘æ§
â”œâ”€ Day 1-2: OOMä¿æŠ¤
â”œâ”€ Day 3-4: æ€§èƒ½è·Ÿè¸ª
â””â”€ Day 4-5: å®Œæ•´æµ‹è¯• + æ–‡æ¡£

Week 3-4 (Phase 3, å¯é€‰): é«˜çº§åŠŸèƒ½
â””â”€ æ ¹æ®v1.1.0æµ‹è¯•ç»“æœå†³å®šæ˜¯å¦å®æ–½
```

---

## ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ç«‹å³å¯æ‰§è¡Œ (ä»Šå¤©)

1. **åˆ›å»ºfeatureåˆ†æ”¯**:
```bash
git checkout -b feature/hardware-optimization
```

2. **åˆ›å»ºæ–°æ–‡ä»¶**:
```bash
touch core/hardware_profiler.py
touch core/performance_profiles.py
touch core/safety_monitor.py
```

3. **å¼€å§‹å®æ–½ä»»åŠ¡1.1**: ç¡¬ä»¶æ£€æµ‹æ¨¡å— (é¢„è®¡2å°æ—¶)

4. **è¿è¡ŒéªŒè¯**:
```bash
python -m pytest tests/test_hardware_profiler.py -v
```

---

**æ–‡æ¡£çŠ¶æ€**: âœ… å¯æ‰§è¡Œ
**æœ€åæ›´æ–°**: 2025-10-14
**è´Ÿè´£äºº**: é™ˆåŒ»ç”Ÿå›¢é˜Ÿ
**ç›®æ ‡å®Œæˆæ—¥æœŸ**: 2025-11-25 (6å‘¨å)
